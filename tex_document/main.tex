%%% ArXiv template from https://www.overleaf.com/latex/templates/an-arxiv-template/gbzmznbxvwpr

\documentclass[10pt]{article}
\usepackage{graphicx}
\baselineskip=16pt

\usepackage{indentfirst,csquotes}

\topmargin= .5cm
\textheight= 20cm
\textwidth= 32cc
\baselineskip=16pt

\evensidemargin= .9cm
\oddsidemargin= .9cm

\usepackage{amssymb,amsthm,amsmath}
\usepackage{xcolor,paralist,hyperref,fancyhdr,etoolbox}


\newtheorem{theorem}{Theorem}[]
\newtheorem{definition}[theorem]{Definition}
\newtheorem{example}[theorem]{Example}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{conjecture}[theorem]{Conjecture}


\hypersetup{colorlinks=true, linkcolor=black, filecolor=black, urlcolor=black }
\def\proof{\noindent {\it Proof. $\, $}}
\def\endproof{\hfill $\Box$ \vskip 5 pt }









%%% PERSONAL ADD-ONS
\usepackage[square,sort,comma,numbers]{natbib}
\usepackage{algorithm}
\usepackage{algpseudocode}
\allowdisplaybreaks
\numberwithin{equation}{section}
%\usepackage{natbib}
\include{macros}

% For foot notes in author name
\newcommand{\footremember}[2]{%
	\footnote{#2}
	\newcounter{#1}
	\setcounter{#1}{\value{footnote}}%
}
\newcommand{\footrecall}[1]{%
	\footnotemark[\value{#1}]%
} 

\begin{document}
	
	
	\title{Ongoing work on MCWAL} %%%%%%%%%%%%
	\author{Pierre Borie\footremember{1}{University of Montreal, Department of Computer Science and Operations Research, Montreal, QC, Canada}}
	\date{}
	
	
	
	\maketitle
	
	\begin{abstract}
		\noindent This informal document deals with the ongoing work and thinking on a algorithm for constrained nonlinear least squares. The current algorithm  name is MCWAL for Moindres Carr\'es With Augmented Lagrangian. Some sections about more general aspects about nonlinear programming might also appear here and there. The aim of this document is to reflect the thinking and understanding of different kinds of notions. 
	\end{abstract} %%%%%%%%% 
	

	\section{Introduction}\label{sec:intro}
	
	We consider least squares problems subject to both nonlinear and linear constraints of the form
	\begin{equation}
		\label{eq:model_cnls}
		\begin{aligned}
			\min_{x\in \RR^n} \quad & \dfrac{1}{2} \|r(x)\|^2 \\
			\text{s.t.} \quad & h(x) = 0 \\
			& \scal{c_i}{x} = b_i,\quad i=1,\ldots,m \\
			& l \le x \le u,
		\end{aligned}
	\end{equation}
	where $r\colon \RR^n \to \RR^d$  and $h\colon \RR^n \to \RR^t$ are assumed to be nonlinear, potentially non convex, continuously differentiable functions, $\scal{\cdot}{\cdot}$ is the canonical inner product and $\|\cdot\| $  its induced euclidean norm, $c_i$ are $m$  independent vectors of $\Real^n$, $( m \le n)$, $b=(b_1,\ldots,b_m)^T \in \RR^m$ and $\ell$ and $u$ are vectors in $\RR^n$. Without loss of generality, some components of the latter two vectors can be set to $\pm \infty$ for unbounded parameters. In the context of least squares problems, components $r_i$ of the function $r$ are often denoted as the residuals.
	
	We will also refer to the linear constraints using the following set notation 
	
	\begin{equation}
		\label{eq:linear_constraints}
		\calX = \left\{ x \in \RR^n \ | \ Cx=b,\ l \le x \le u\right\},
	\end{equation}
	where $C$ is the matrix whose columns are the vectors $c_i$. By linear independence of those vectors, $C$ is a full rank matrix. The set $\calX$ is thus convex.
	
	\subsection{Notations}
	 
	
	The Jacobian matrix of constraints function $h$ is noted $A$.
	
	When considering iterative methods for solving problem~\eqref{eq:model_cnls}, $k$ will, if not mentioned otherwise, refer to the iteration number. In order to simplify notations, quantities relative to a given iteration will be noted with the iteration number as an index, such as $x_k$ for the iterate, $r_k$ for $r(x_k)$ ,$J_k$ for $J(x_k)$ etc.
	
	Symbol $:=$ shall be used to state the definition of a numerical object (function, vector etc.)
	
	For a set $E$, a sequence $(x_k)_k$ converging to $x^* \in E$ when $k\to+\infty$, we will write $x_k \to_E x^*$ if, above a certain index, all $x_k$ are in $E$. 
	
	\subsection{Optimality conditions for nonlinear programming}
	
	In this section, we describe optimality conditions for nonlinear programs more general than~\eqref{eq:model_cnls} from different views.
	
	\subsubsection{An algebraic view}
	
	We consider the general mathematical program\footnote{Shall I write the KKT conditions w.r.t this formulation and then consider multipliers for the bounds?}
	\begin{equation}
		\label{eq:math_prog}
		\begin{aligned}
			\min_x \quad & f(x) \\
			\text{s.t.} \quad & h(x)=0 \\
			& l \le x \le u,
		\end{aligned}
	\end{equation}
	with the same assumptions on of differentiability of functions $f$ and \(h\). We introduce the Lagrangian associated to problem~\eqref{eq:math_prog}:
	\begin{equation}
		\label{eq:lagrangian}
		\ell(x,\lambda) = f(x) + \scal{\lambda}{h(x)},
	\end{equation}
	where $\lambda$ is the vector of Lagrange multipliers. Algorithms discussed aim to find local minimum of problem~\eqref{eq:math_prog}, i.e. feasible and of minimal value in s neighborhood. Under suitable assumptions, one can establish necessary and even sufficient conditions for local optimality. One of the most important assumptions belongs to the familty of constraints qualifications. The following is the one we will employ.
	
	\begin{definition}\label{def:licq}
		\textbf{(LICQ)}
		The LICQ holds at $x^*$ if the gradients of the equality constraints evaluated at $x^*$ are linearly independent. In other terms, the matrix $A(x)$ is full rank.
	\end{definition}
	
	Using this and standard differentiability assumptions, one can state first-order necessary optimality conditions, also known as KKT conditions. 
	
	\begin{definition}\label{def:kkt_point}
		\textbf{(KKT conditions)}
		A point $x^*$ satisfies the KKT conditions if $x^* $ is feasible and there exists multipliers \(\lambda^*\) such that \[\nabla_x \ell (x^*,\lambda^*)=0.\]
	\end{definition}
	
	
	A point satisfying those conditions if also said to be a KKT point or a first order critical point for problem~\eqref{eq:math_prog}. Depending on the context, we would refer to a KKT point either by just wrting $x^*$ or the couple formed after $x^*$ and its associated Lagrange multiplier $\lambda^*$The necessary conditions follow.
	
	\begin{theorem}\label{theo:fonc}
		\textbf{(First Order Necessary Conditions)\cite[][Theorem 12.1]{nocedalwright:2006}}
		Let $x^*$ be a local solution of~\eqref{eq:math_prog} at which the LICQ holds. Then $x^*$ is a KKT point.
	\end{theorem}
	
	Sufficient optimality conditions can be established using second order information.
	
	\begin{definition}\label{def:soc}
		\textbf{(Second Order Conditions)}
		A point $(x^*,\lambda^*)$ satisfies the second order conditions if it is a KKT point for ~\eqref{eq:math_prog} at which the LICQ holds and if the matrix $\nabla_{xx}^2\ell(x^*,\lambda^*)$ is positive definite on the null space of the constraints Jacobian, i.e.:
		\[\forall w \text{ verifying } \scal{A(x^*)}{w}=0,\ \scal{w}{\nabla_{xx}^2\ell(x^*,\lambda^*)w} > 0.\]
	\end{definition}
	
	\begin{theorem} \textbf{(Second Order Sufficient Conditions) \cite[][Theorem 12.5]{nocedalwright:2006}}
		If $x^*$ satisfies the second order conditions, then $x^*$ is a local minimum of~\eqref{eq:math_prog}.
	\end{theorem}
	
	\subsubsection{A geometric view}
	
	We now consider the general program
	
	\begin{equation}
		\label{eq:math_prog_geom}
		\begin{aligned}
			\min_x \quad & f(x) \\
			\text{s.t.} \quad & x \in \calC,
		\end{aligned}
	\end{equation}
	
	where the feasible set $\calC$ is a (of course non empty), subset of $\RR^n$. The idea is to describe optimality conditions using inclusions of certain vectors to sets and cones. General results can be stated without any further assumptions on $\calC$. Yet, we will give important results about projections that require to assume $\calC$ is convex. As we shall see in section~\ref{sec:about_al}, our method will imply solving quadratic programs subject to linear, hence convex, constraints. Most of the content exposed is from~\cite[][Chapter 12]{nocedalwright:2006}.
	
	We start by defining two important sets, that are acutally cones. We remind that a set $K$ is a cone if for all $x \in K$ and $\alpha >0 $, $\alpha x\in K $. A cone is pointed if it contains $0$.
	
	\begin{definition}\textbf{Tangent Vector}
		Let $x\in \calC$. A vector $v\in \RR^n$ is said to be a tangent vector to $\calC$  at $x$ if there are sequences $(x_k)_k \to_\calC x$ and $(t_k)_k \searrow 0^+$ such that 
		\[\lim\limits_{k\to \infty} \dfrac{x_k-x}{t_k}=v.\]
	\end{definition}
	
	\begin{definition}
		
	The \textbf{tangent cone} is the set of all tangents vectors to $\calC$ at $x$ and is denoted by $T_\calC(x)$.
	\end{definition}
	
	For a better understanding, the limit in the definition can be written as the relation
	\[x_k - x = t_kv + o(1).\]
	Intuitively, tangent vectors are all the directions going from $x$ that stay in $\calC$, up to a scaling by a very small positive factor. In the context of constrained optimization, they characterize directions in which one can step away from $x$ while remaining feasible. 
	
	\textbf{Remark} 
	
	Rigorously, it is a $o(t_k)$ but since $t_k \to 0$, a $o(t_k)$ is also a $o(1)$. Our intent is to highlight the  visualization of a tangent vector as a scaled $x_k-x$ for $(x_k)_k \to x$.
	
	\begin{definition}
		
		The \textbf{normal cone} to $\calC$ at $x$ is the set defined by
		\[N_\calC (x) := \left\{w \in \RR^n\ | \ \forall v \in T_\calC(x), \scal{v}{w} \le 0\right\}.\]
	\end{definition}
	
	The normal cone is merely the orthogonal complement of the tangent cone and is involved in the following first order optimality condition.
	
	\begin{theorem}\label{theo:first_order_normal_cone}
		If $x^*$ is a local minimum of $f$, then \[-\nabla f(x^*) \in N_\calC(x^*).\]
	\end{theorem}
	
	This theorem reflects the intuitive fact that a local minimum is a point from which the objective function cannot be reduced while remaining feasible. While this result is simple is elegant, its use is limited by the difficulty to express both tangent and normal cones without any other assumptions. For instance, with the LICQ, the tangent cone can be expressed as an intersection of hyperplanes depending on the constraints gradients and combining theorem~\ref{theo:first_order_normal_cone} with a Farkas-like lemma gives the KKT conditions. Similar consequences occur when the feasible set is convex, which we will assume from now on.
	
	We first remind the definition a convex set.
	
	\begin{definition}
		A set $\calC\subseteq \RR^n$ is \textbf{convex} if \(\forall (x,y) \in \calC^2\) and \(\ \alpha \in [0,1] \), one has \(\alpha x+ (1-\alpha)y \in \calC\).
		In other words, the line segment between two points remains in $\calC$, for all points of $\calC$.
	\end{definition}
	
	In this setting, the normal cone can be described more simply.
	
	\begin{proposition}\label{prop:normal_set_convex}
		Let $\calC $ a non empty convex set. Then for all $x \in \calC$:
		\[N_\calC (x) = \left\{v \ | \ \forall y \in \calC, \scal{v}{x-y} \ge 0\right\}.\]
		For $x \notin \calC$, $N_\calC (x) = \emptyset$.
	\end{proposition}
	
	Then, if $x^*$ is a local minima of~\eqref{eq:math_prog_geom}, the inclusion in theorem~\ref{theo:first_order_normal_cone}  becomes
	\begin{equation}\label{eq:fo_optimality_convex_set}
		\forall x \in \calC, \scal{\nabla f(x^*)}{x-x^*} \ge 0.
	\end{equation}
	
	\textbf{Remarks on~\eqref{eq:fo_optimality_convex_set}}
	\begin{enumerate}
		\item This condition if sufficient when the function $f$ is convex
		\item It also reflects the very visual fact that in $\RR^2$, the line tangent to a local minima is below the curve
	\end{enumerate}
	
	So we now have a more simple way to characterize a minimum but it is still not suited to be used in algorithms. Obviously, one cannot check the sign of an infinite number of inner product but more fundamentally, algorithm must be able to manipulate points that are likely to be outside of the feasible set. Using projections is the key.
	
	\begin{definition}\label{def:projection}
		
		Let $\calC \subseteq \RR^n$. The \textbf{projection operator} is the set-value mapping $P_\calC \colon \RR^n \rightrightarrows \calC $ defined by
		\[ P_C(\bar{x}) = \argmin_{y \in \calC}  \dfrac{1}{2} \|x-y\|^2.\]
	\end{definition}
	
	For this definition, we introduce the notion of set-value mapping~\cite{rockafellarwets:1998} to remain general but in the convex case, it is single valued and well defined if the concerned set is closed. 
	
	\begin{theorem}
		Let $\calC$ be a close convex set and $x \in \RR^n$. Then
		\[\bar{x} = P_\calC(x) \iff \forall y \in \calC, \scal{\bar{x}-x}{y-\bar{x} \ge 0.}\]
	\end{theorem}
	
	Since the norm is convex, this theorem is simply derived from the first order necessary optimality  conditions. Also the inequality kind of looks like the inequality in proposition~\eqref{prop:normal_set_convex}, which motivates the following theorem.
	
	\begin{theorem}
		Let $\calC$ be a close convex set, $x \in \RR^n$ and $z \in \calC$. Then
		\[z = P_\calC(x) \iff (x-z) \in N_\calC(z).\]
	\end{theorem}
	
	From this result, one deduces the following useful corollary.
	
	\begin{corollary}
		Let $\calC$ be a close convex set, $x \in \calC$ and $z \in \RR^n$. If $z \in N_\calC(x)$, then $\forall t\ge 0$, $P_\calC(x+tz)=x$.
	\end{corollary}
	
	Applying the above corollary to opposite of the gradient of a local minimum, thus verifying theorem~\ref{theo:first_order_normal_cone}, gives the next theorem.
	
	\begin{theorem}
	Consider the problem~\eqref{eq:math_prog_geom} where the non empty feasible set $\calC$ is closed and convex. Then $x^*$ is a local minimum if and only if for all $t \ge 0$, $P_\calC\left(x^*-t\nabla f(x^*)\right)=x^*$.
	\end{theorem}
	
	There is our desired result that we shall use as a termination criteria, up to a small tolerance. In practice, we will work with the Cauchy arc defined as
	
	\begin{equation}\label{eq:cauchy_arc}
		p(t,x) := P_\calC(x-t\nabla f(x)),
	\end{equation}
	
	that is the path alongside the steepest descent direction. The Cauchy point is the point minimizing the objective function on the Cauchy arc, i.e.:
	
	\begin{equation}
		x^C := x - t^C \nabla f(x) \text{ where } t^C = \argmin_{t \ge 0} f\left(p(t,x)\right).
	\end{equation}
	
	If an algorithm uses the Cauchy point as the new iterate, then the algorithm would converge. Moreover, if each iterate reduces the objective function as much as a fraction of the Cauchy point, the algorithm would also converge. This pretty much sets the foundation, and intuition, for the theory of convergence for algorithms producing inexact solutions of the sub problems, especially for trust regions methods~\cite{conn-etal:2000}. In a less formal way, it translates into a theoretical notion the practical aspect that computers are by nature inexact, because of floating-point arithmetic, and thus we are more interested into proving that "not exact but good enough" solutions will do the job. An algorithm that does not converge if solutions are not exact might be nice on paper but will not be very useful in practice.
	
	\subsection{Generalities on least squares}
	 
	 Rewriting the objective function of problem~\eqref{eq:model_cnls} as $f\colon x \mapsto  \frac{1}{2} \|r(x)\|^2$, one has:
	 
	 \begin{subequations}
	 		\begin{align}
	 		\nabla f(x) &= J(x)^Tr(x)\label{subeq:ls_grad} \\
	 		\nabla^2 f(x) &= J(x)^TJ(x) + S(x) , \label{subeq:ls_hessian}
	 		\end{align}
	 \end{subequations}
	 where $J(x) = \left[\dfrac{\partial r_i}{\partial x_j}\right]_{(i,j)}$ is the Jacobian matrix of the residuals and the second component of the Hessian $S(x) = \sum_{i=1}^{d} r_i(x) \nabla^2r_i(x) $. The latter is expensive in both computational time and storage, since it requires $d$ computations of $n\times n$ matrices. Hence, this component of the Hessian is the one to be approximated. 
	 
	 The Jacobian matrix of constraints function $h$ is noted $A$.
	 
	 When considering iterative methods for solving problem~\eqref{eq:model_cnls}, $k$ will, if not mentioned otherwise, refer to the iteration number. In order to simplify notations, quantities relative to a given iteration will be noted with the iteration number as an index, such as $x_k$ for the iterate, $r_k$ for $r(x_k)$ ,$J_k$ for $J(x_k)$ etc.
	 
	 Symbol $:=$ shall be used to state the definition of a numerical object (function, vector etc.)
	 
	 We now address is a quick review of the three most popular classes of approximations. For a comprehensive review of these methods, we refer the reader to the chapter 10 of \cite{dennisschnabel:1996}.
	 
	 \subsubsection{Gauss-Newton method}
	 
	 Originally used by Gauss the prince himself, \textbf{Gauss--Newton} (GN) approximation sets $S(x)$ to the zero matrix. It is the cheapest to compute, since the Jacobian is necessary to evaluate the gradient and works well in practice for zero residuals problems~\cite{dennisschnabel:1996}. When solving problem~\eqref{eq:model_cnls} using an iterative method, this approximation amounts to linearizing the residuals function within the norm. Indeed, approximating $\nabla f^2(x)$ by $J(x)^TJ(x)$ in a quadratic model $\calQ$ of $f$ around $x$ gives
	 
	 \begin{equation}\label{eq:gn_model}
	 	\calQ^{GN} (p) = \dfrac{1}{2}p^T\nabla f^2(x)p + \nabla f(x)^Tp =  \dfrac{1}{2} \left\Vert J(x)p+r(x) \right\Vert^2,
	 \end{equation}
	 
	 which corresponds to injecting the linearization $r(x+p) \approx J(x)p+r(x)$ in the squared norm.
	 
	 \subsubsection{Levenberg-Marquardt}
	 
	 Next, we describe the \textbf{Levengerg--Marquardt} (LM) method, respectively named after the first author to publish it~\cite{levenberg:1944} and the author of its best-known rediscovery~\cite{marquardt:1963}. As noted by Marquardt in his paper, the two authors started from a different line of reasoning but came to the same conclusion. In this method, matrix $S(x)$ is set to a multiple of the identity matrix $\sigma I$ where $\sigma$ is a positive scalar. The latter is called regularization parameter, because setting  $\nabla f^2(x)$ to $J(x)^TJ(x)$ leads to the quadratic model 
	 
	 \begin{equation}\label{eq:lm_model}
	 	\calQ^{LM}(p) =  \dfrac{1}{2} \left\Vert J(x)p+r(x) \right\Vert^2 + \dfrac{\sigma}{2} \|p\|^2.
	 \end{equation}
	 
	 In other words, one can see very schematically that
	 
	\[\text{LM model} = \text{GN model} + \text{regularization term}.\]
	
	In practice, the LM approximation works well on zero and small residuals problems and tends to be more robust than the GN approximation. It is still cheap to compute but only requires updating the regularization parameter throughout the iterative process. This method is often referred as the early stage of the trust region methods~\cite{conn-etal:2000}. For the link with regularization methods, consider the trust region problem
	 
	 \begin{equation*}
	 	\begin{aligned}
	 		\min_x \quad & f(x) \\
	 		\text{s.t.} \quad & \|x\| \le \Delta.
	 	\end{aligned}
	 \end{equation*}
	 
	 By applying KKT conditions and assuming that there is a minimizer $x^*$ lying on the trust region, i.e. $\|x^*\|=\Delta$, then (under strict complementarity), there is a strictly positive scalar (the multiplier) $\lambda$ such that
	 \[\nabla f(x^*) + \dfrac{2\lambda}{\Delta}x^*=0.\]
	 
	 As a consequence, $x^*$ is a critical point oh the unconstrained regularized problem
	 
	 \[\min_x \quad f(x) + \dfrac{\delta}{2} \|x\|^2,\]
	 
	 where $\delta=\frac{2\lambda}{\Delta}$.
	 
	 Some references for LM methods: \cite{bellavia-etal:2018}
	 
	 \subsubsection{Quasi-Newton}
	 
	 Finally, one can compute an approximation of $\nabla^2f(x)$ in a similar pattern as in \textbf{quasi-Newton} methods \cite[][Chapter 6]{nocedalwright:2006} but targeted on the second order components. It has a higher computational cost than the previous two but is more accurate on large residuals problems. In~\cite{dennisetal:1981}, the authors exploit this approach in a adaptative scheme, where an estimation of the curvature is used to decide whether or not the quasi-Newton approximation is worth to use compared to the Gauss-Newton one.
	 
	 It is important to bear in mind that choosing between a "cheap" approximation and a quasi-Newton type one implies making compromises. Depending on the initialization, the quasi-Newton approximation will take some iterations to be good and the accuracy will not be there when most needed, i.e. at the starting point potentially far from the solution, and will match the Gauss-Newton close to the solution on small residuals problems. In other words, the quasi-Newton is not accurate enough when most needed and very accurate when a way cheaper alternative does the same job.
	 
	 References for quasi-Newton specialized to least-squares: \cite{dennisetal:1981,yabetakahashi}.
	 
	 \section{Augmented Lagrangian reformulation}\label{sec:about_al}
	 
	 In this section, we introduce the framework of Augmented Lagrangian-based algorithms and describe an application in the least-squares setting of problem~\eqref{eq:model_cnls}.
	 
	 \subsection{Generalities}
	 
	 In order to remain general, we temporarily consider the mathematical program~\eqref{eq:math_prog} and shall comeback to our beloved least-squares shortly after. 
	 We introduce the Augmented Lagrangian (AL) function associated to program~\eqref{eq:math_prog}:
	 
	 \begin{equation}
	 	\label{eq:al}
	 	\Phi_A(x,\lambda,\mu) := f(x) + \scal{\lambda}{h(x)} + \dfrac{\mu}{2} \|h(x)\|^2,
	 \end{equation}
	 
	 where $\lambda\in \Real^m$ is the vector of Lagrange multipliers and $\mu > 0$ is the penalty parameter.
	 
	 Function~\eqref{eq:al} is nothing than the Lagrangian~\eqref{eq:lagrangian} with a quadratic penalty term, hence the adjective \textit{Augmented}.Assume we fixed $\lambda$ and $\mu$, the problem of interest is now the bound constrained program
	 
	 \begin{equation}\label{eq:al_nlp}
	 	\begin{aligned}
	 		\min_x \quad & \Phi_A(x,\lambda,\mu) \\
	 		\text{s.t.} \quad & l \le x \le u.
	 	\end{aligned}
	 \end{equation}
	 
	 AL-based algorithms fall into the class of penalty methods that generally enable one to use iterative methods for unconstrained optimization  while steel achieving feasibility. In our case, moving the nonlinear constraints into the objective simplifies the set of constraints since only bounds constraints are left.
	 
	 One of the pros of AL methods is that they come naturally with an update formula for the multipliers. Let \((x_k,\lambda_k)\) be the current primal-dual iterate, then one can choose \(\lambda_{k+1} \) as
	 
	 \begin{equation}\label{eq:al_multipliers_update}
	 	\lambda_{k+1} = \lambda_k + \mu_kh(x_k).
	 \end{equation}
	 
	 This relation is merely derived from \(\nabla_x\Phi_A=0\) by identifying the right hand side of equation~\eqref{eq:al_multipliers_update} as multipliers satisfying the KKT condition \(\nabla_x \ell =0\).
	 
	 The procedure of an AL method is relatively  and relies on solving successively  problem~\eqref{eq:al_nlp} with respect to the primal variable until a first order critical point of the original problem~\eqref{eq:math_prog} is found. At every iteration, the penalty parameter is increased and the multipliers are updated by formula~\eqref{eq:al_multipliers_update}. This general pattern is outlined in algorithm~\ref{algo:basic_al} and the main steps of the outer iteration are given in  algorithm~\ref{algo:outer_basic_al_trm}.
	 
	 	\begin{algorithm}
	 		\caption{Basic AL algorithm for solving~\eqref{eq:math_prog}}\label{algo:basic_al}
	 		\begin{algorithmic}
	 			\Require Starting point $\left(x_0^s,\lambda_0\right)$, parameter $\mu_0$  parameter $\mu_0$ and tolerances $\omega_*,\omega_0,\eta_*,\eta_0$.
	 			\Repeat
	 			 \State Compute an approximate solution $x_{k}$ of~\eqref{eq:al_nlp} starting from \(x_k^s\) with tolerance $\omega_k$.
	 			\If{\(\|h(x_k)\| < \eta_k\)}
	 				\State Update iterate and increase penalty parameter.
	 				\Else
	 					\State Restart minimization of~\eqref{eq:al_nlp} with a higher penalty parameter.
	 			\EndIf
	 			\State Update tolerances
	 			\Until{\(\|h(x_k)\| < \eta_*\) \textbf{and}  \(\|\nabla_x \ell(x_k,\lambda_k)\| < \omega_*\)}
	 			\State Return current approximate solution.
	 		\end{algorithmic}
	 	\end{algorithm}
	 	
	 	\begin{algorithm}
	 	\caption{Outer iteration of basic AL algorithm with trust region}\label{algo:outer_basic_al_trm}
	 		\begin{enumerate}
	 		\item[\textbf{Step 1: Inner Iteration}]
	 		
	 		Starting from $x_0^s$, approximately solve $\min_x \Phi_A(x,y_k,\mu_k)$ by computing $x_k$ such that \(\left\Vert x_k - P(x_k-\nabla_k\Phi_A)\right\Vert \le \omega_k\)
	 		by a trust region process.
	 		
	 		\textbf{If} $\|h(x_k)\| \le \eta_k$, execute \textbf{Step 2}.
	 		
	 		Otherwise, excecute \textbf{Step 3}.
	 		
	 		\item[\textbf{Step 2: Iterate Update}]
	 		
	 		Update $y_{k+1}$ by formula~\eqref{eq:al_multipliers_update} and set $x_{k+1}^s \gets x_k $.
	 		
	 		Choose new tolreances \(\omega_{k+1}, \eta_{k+1}\) and new penalty parameter \(\mu_{k+1}\).
	 		
	 		Increment $k$ and go back to \textbf{Step 1}.
	 		
	 		\item[\textbf{Step 3: Adjustment of the Penalty Parameter}] 
	 		
	 		Choose $\mu_{k+1}$ significantly greater than $\mu_k$.
	 		
	 		Leave the iterate unchanged: \(\left(x_{k+1}^s,\lambda_{k+1}\right) \gets \left(x_k^s,\lambda_k\right)\).
	 		
	 		Go back to \textbf{Step 1}.
	 	\end{enumerate}
	 \end{algorithm}
	 
	 \textbf{TODO How to compute the approximate minimizer? Projected conjugate gradient!}
	 \subsection{Application to structured least-squares}
	 
	 We now consider program~\eqref{eq:model_cnls}, for which the AL function is given by
	 
	 \begin{equation}
	 	\label{eq:lsal}
	 	\Phi_A(x,\lambda,\mu) := \dfrac{1}{2}\|r(x)\|^2 + \scal{\lambda}{h(x)} + \dfrac{\mu}{2} \|h(x)\|^2,
	 \end{equation}
	 
	 Contrary to formulation~\eqref{eq:al}, we keep the linear equality constraints as is and penalize the violation of the nonlinear constraints. Although the computation of the projection onto the set $\calX$ shall differ, the framework remains the same, 
	 One has the following expression of the gradient: 
	 \begin{equation}
	 	\label{eq:al_grad}
	 	\nabla_x \Phi_A(x,\lambda,\mu) = J(x)^Tr(x) + A^T\pi(x,\lambda,\mu),
	 \end{equation}
	 with $\pi(x,\lambda,\mu):=\lambda + \mu h(x)$ is the first-order estimates of the Lagrange multipliers. 
	 
	 The Hessian is given by
	 \begin{equation}\label{eq:al_hessian}
	 	\nabla^2_{xx} \Phi_A(x,\lambda,\mu) = J(x)^TJ(x) + \mu A(x)^TA(x) +  S(x) + \sum_{i=1}^d \nabla^2 h_i(x) \pi(x,\lambda,\mu).
	 \end{equation}
	 
	 For fixed $\lambda$ and $\mu$, reformulating problem~\eqref{eq:model_cnls} with function~\eqref{eq:al} gives the linearly constrained problem
	 
	 \begin{equation}\label{eq:model_cnls_al_reformulation} 
	 	\begin{aligned}
	 		\min_{x} \quad& \Phi_A(x,\lambda,\mu)  \\
	 		\text{s.t.}  \quad & x \in \calX 
	 	\end{aligned}	
	 \end{equation}
	 
	 As for any other AL based algorithm, the idea behind MCWAL is to solve by an iterative method problem~\eqref{eq:model_cnls_al_reformulation} until a first order critical point of problem~\eqref{eq:model_cnls} is found. At every iteration, a the new iterate will be computed after (approximately) solving a trust region subproblem formed after a quadratic model of the AL around the current iterate. 
	 
	 \subsection{Subproblem}
	 
	 Given a primal-dual iterate $(x_k,\lambda_k)$ and a penalty parameter $\mu_k$, we consider a quadratic model of the AL around $x_k$:
	 
	 \begin{equation}\label{eq:quadratic_al}
	 	\calQ_k(p) = \dfrac{1}{2}\scal{p}{H_kp} + \scal{g_k}{p},
	 \end{equation}
	 
	 where $H_k:=\nabla^2_{xx} \Phi_A(x_k,\lambda_k,\mu_k)$ or an approximation of it and $g_k:=\nabla_x \Phi_A(x_k,\lambda_k,\mu_k)$.
	 
	 Vector $p$ denotes the unknown of the subproblem whose (approximate) solution $p_k$ shall be used to compute the new iterate $x_{k+1}=x_k+p_k$.
	 
	 For the linear constraints, we want $x_k+p\in \calX$ which will be provided if:
	 \begin{itemize}
	 	\item \(Cp=0\) (provided that $Cx_0=b$)
	 	\item$ x_k-l \le p \le u-x_k$
	 \end{itemize}
	 The above conditions shall be written $p\in \calX_k$ where $\calX_k:= \left\{p \ | \ Cp=0,\ x_k-l \le p \le u-x_k\right\}$.
	 
	As part of our method, we will also add a trust region constraint of the form $\|p\|_k \le \Delta_k$ for a radius $\Delta_k$ and a norm $\|\cdot\|_k$. Index $k$ in the latter means that the norm might depend on the iteration. A priori, we would use the euclidean norm.
	
	The subproblem of an outer iteration is then given by
	
	\begin{equation}\label{eq:quadratic_subpb} 
		\begin{aligned}
			\min_{p\in \calX_k} \quad& \calQ_k(p)  \\
			\text{s.t.}  \quad &  \|p\|_k \le \Delta_k.
		\end{aligned}	
	\end{equation}
	
	A first sketch of the MCWAL procedure is drawn in algorithm~\ref{algo:sketch_mcwal}.
	 \begin{algorithm}
	 	\caption{Sketch of MCWAL}\label{algo:sketch_mcwal}
	 	\begin{algorithmic}
	 		\Require $x_0\in \calX$, $\lambda_0$, $\mu_0, \tau_0$ and constants $\eta_s$
	 		\While{\textbf{not optimal}\footnote{replace with a numerical criteria corresponding to KKT condition}}
	 		\State Evaluate $H_k$ and $g_k$ 
	 		\State Compute a solution $p_k$ of subproblem~\eqref{eq:quadratic_subpb} 
	 		\State Compute ratio $\rho_k$\footnote{TODO: define its expression}
	 		\If{$\rho_k \ge \eta_s$} \Comment{Good step}
	 		\State $x_{k+1} \gets x_k+p_k$
	 		\State Choose $\Delta_{k+1} > \Delta_k$
	 		\If{$\|h(x_k)\| \le \tau_k$}
	 		\State $y_{k+1} \gets \pi(x_k,y_k,\mu_k)$
	 		\State Choose $\mu_{k+1} > \mu_k$ and $\tau_{k+1} < \tau_k$
	 		\Else
	 		\State $y_{k+1} \gets y_k$
	 		\State Choose $\mu_{k+1} < \mu_k$
	 		\EndIf
	 		\Else \Comment{Bad step}
	 		\State  $x_{k+1} \gets x_k$
	 		\State  $y_{k+1} \gets y_k$
	 		\State  $\mu_{k+1} \gets \mu_k$
	 		\State Choose $\Delta_{k+1} < \Delta_k$
	 		\EndIf
	 		\EndWhile
	 	\end{algorithmic}
	 \end{algorithm}
	

	\clearpage
	
	\bibliographystyle{plainnat}
	\bibliography{refs}
\end{document}